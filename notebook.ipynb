{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECSE556 - HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "import os\n",
    "\n",
    "np.random.seed(0)  # fixing the seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"data\", \"gdsc_expr_postCB.csv\")\n",
    "data = pd.read_csv(data_path, index_col=0, header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transpose the dataframe because the standard is to have the columns be the features and the rows the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.transpose()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into training and evaluation, to avoid data leakage and biases. (seed is fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "df_train = pd.DataFrame(train)\n",
    "df_test = pd.DataFrame(test)\n",
    "print(f\"Shape of training set: {train.shape}\")\n",
    "print(f\"Shape of test set: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the dataset. Most algorithm work best when the data are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_scaler = StandardScaler()\n",
    "np_train_scaled = features_scaler.fit_transform(df_train)\n",
    "df_train_scaled = pd.DataFrame(\n",
    "    np_train_scaled, index=df_train.index, columns=df_train.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "np_pca_projected = pca.fit_transform(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pca_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=np_pca_projected[:, 0], y=np_pca_projected[:, 1])\n",
    "plt.title(\"PCA dimensionality reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=2000, random_state=0)\n",
    "np_tsne_projected = tsne.fit_transform(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_tsne_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=np_tsne_projected[:, 0], y=np_tsne_projected[:, 1])\n",
    "plt.title(\"t-SNE dimensionality reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_umap_projected = UMAP().fit_transform(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_umap_projected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=np_umap_projected[:, 0], y=np_umap_projected[:, 1])\n",
    "plt.title(\"UMAP dimensionality reduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.scatterplot(x=np_pca_projected[:, 0], y=np_pca_projected[:, 1], ax=axes[0])\n",
    "axes[0].set_title(\"PCA\")\n",
    "\n",
    "sns.scatterplot(x=np_umap_projected[:, 0], y=np_umap_projected[:, 1], ax=axes[1])\n",
    "axes[1].set_title(\"UMAP\")\n",
    "\n",
    "sns.scatterplot(x=np_tsne_projected[:, 0], y=np_tsne_projected[:, 1], ax=axes[2])\n",
    "axes[2].set_title(\"t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the three methods produce very different representations of the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative and K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo = AgglomerativeClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_clustering = agglo.fit_predict(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agglo_clustering = pd.DataFrame(agglo_clustering, index=df_train_scaled.index)\n",
    "df_agglo_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_clustering.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(agglo_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_clustering = kmeans.fit_predict(df_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k_clustering = pd.DataFrame(k_clustering, index=df_train_scaled.index)\n",
    "df_k_clustering.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_clustering.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(k_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of samples attributed to each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For agglomerative clustering:\")\n",
    "for i in range(3):\n",
    "    print(f\"Number of samples in cluster {i}: {np.sum(agglo_clustering == i)}\")\n",
    "print(\"For K-means clustering:\")\n",
    "for i in range(3):\n",
    "    print(f\"Number of samples in cluster {i}: {np.sum(k_clustering == i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that the proportion of samples in each cluster is very close. For further comparison of the methods, we should see if the samples belong to the same clusters. This is what we do in the following section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two distributions of classes on each subplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].set_title(\"Agglomerative Clustering\")\n",
    "axes[1].set_title(\"K-Means Clustering\")\n",
    "# hist plot\n",
    "sns.histplot(agglo_clustering, ax=axes[0], discrete=True, stat=\"percent\", shrink=0.9)\n",
    "axes[0].xaxis.set_ticks([0, 1, 2], [\"Cluster-0\", \"Cluster-1\", \"Cluster-2\"])\n",
    "sns.histplot(k_clustering, ax=axes[1], discrete=True, stat=\"percent\", shrink=0.9)\n",
    "axes[1].xaxis.set_ticks([0, 1, 2], [\"Cluster-0\", \"Cluster-1\", \"Cluster-2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the clusters on the 2D-projections from part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters from the agglomerative method visualized on the 2D-projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dictionary of Seaborn palettes\n",
    "seaborn_palettes = sns.palettes.SEABORN_PALETTES\n",
    "\n",
    "# Get the list of palette names\n",
    "palette_names = list(seaborn_palettes.keys())\n",
    "\n",
    "# Print the list of palette names\n",
    "print(palette_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.scatterplot(x=np_pca_projected[:, 0], y=np_pca_projected[:, 1], ax=axes[0], hue=agglo_clustering, palette=\"muted6\")\n",
    "axes[0].set_title(\"PCA\")\n",
    "\n",
    "sns.scatterplot(x=np_umap_projected[:, 0], y=np_umap_projected[:, 1], ax=axes[1], hue=agglo_clustering, palette=\"muted6\")\n",
    "axes[1].set_title(\"UMAP\")\n",
    "\n",
    "sns.scatterplot(x=np_tsne_projected[:, 0], y=np_tsne_projected[:, 1], ax=axes[2], hue=agglo_clustering, palette=\"muted6\")\n",
    "axes[2].set_title(\"t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clusters from the k-means clustering method visualized on the 2D-projections from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.scatterplot(x=np_pca_projected[:, 0], y=np_pca_projected[:, 1], ax=axes[0], hue=k_clustering, palette=\"muted6\")\n",
    "axes[0].set_title(\"PCA\")\n",
    "\n",
    "sns.scatterplot(x=np_umap_projected[:, 0], y=np_umap_projected[:, 1], ax=axes[1], hue=k_clustering, palette=\"muted6\")\n",
    "axes[1].set_title(\"UMAP\")\n",
    "\n",
    "sns.scatterplot(x=np_tsne_projected[:, 0], y=np_tsne_projected[:, 1], ax=axes[2], hue=k_clustering, palette=\"muted6\")\n",
    "axes[2].set_title(\"t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacard similarity scores between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = np.zeros((3, 3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        similarity_score = jaccard_score(\n",
    "            (agglo_clustering == i).astype(\"int32\"), (k_clustering == j).astype(\"int32\")\n",
    "        )\n",
    "        similarity_scores[i, j] = similarity_score\n",
    "        print(f\"Similarity score for clusters {i} vs {j}: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similarity_scores = pd.DataFrame(\n",
    "    similarity_scores,\n",
    "    columns=[\"Cluster 0\", \"Cluster 1\", \"Cluster 2\"],\n",
    "    index=[\"Cluster 0\", \"Cluster 1\", \"Cluster 2\"],\n",
    ")\n",
    "df_similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concordance scores between clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import rand_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = rand_score(agglo_clustering, k_clustering)\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand = adjusted_rand_score(agglo_clustering, k_clustering)\n",
    "adjusted_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variations of the Agglomerative Clustering method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try variations of the Agglomerative Clustering method by using different distance metrics that we want to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_cosine = AgglomerativeClustering(n_clusters=3, metric=\"cosine\", linkage=\"average\")\n",
    "agglo_eucli = AgglomerativeClustering(\n",
    "    n_clusters=3, metric=\"euclidean\", linkage=\"average\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_cosine_clusters = agglo_cosine.fit_predict(df_train_scaled).astype(\"int32\")\n",
    "agglo_eucli_clusters = agglo_eucli.fit_predict(df_train_scaled).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's observe the size of each cluster, for each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(agglo_cosine_clusters))\n",
    "print(np.unique(agglo_eucli_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the two distributions of classes on each subplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].set_title(\"Cosine distance\")\n",
    "axes[1].set_title(\"Euclidean distance\")\n",
    "# hist plot\n",
    "sns.histplot(\n",
    "    agglo_cosine_clusters, ax=axes[0], discrete=True, stat=\"percent\", shrink=0.9\n",
    ")\n",
    "axes[0].xaxis.set_ticks([0, 1, 2], [\"Cluster-0\", \"Cluster-1\", \"Cluster-2\"])\n",
    "sns.histplot(\n",
    "    agglo_eucli_clusters, ax=axes[1], discrete=True, stat=\"percent\", shrink=0.9\n",
    ")\n",
    "axes[1].xaxis.set_ticks([0, 1, 2], [\"Cluster-0\", \"Cluster-1\", \"Cluster-2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Euclidian distance with the agglomerative method yields a poor representation of the dataset, as all the samples are attributed to the same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the clusters generated using the cosine distance on the 2D-projection from part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "sns.scatterplot(x=np_pca_projected[:, 0], y=np_pca_projected[:, 1], ax=axes[0], hue=agglo_cosine_clusters, palette=\"muted6\")\n",
    "axes[0].set_title(\"PCA\")\n",
    "\n",
    "sns.scatterplot(x=np_umap_projected[:, 0], y=np_umap_projected[:, 1], ax=axes[1], hue=agglo_cosine_clusters, palette=\"muted6\")\n",
    "axes[1].set_title(\"UMAP\")\n",
    "\n",
    "sns.scatterplot(x=np_tsne_projected[:, 0], y=np_tsne_projected[:, 1], ax=axes[2], hue=agglo_cosine_clusters, palette=\"muted6\")\n",
    "axes[2].set_title(\"t-SNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters found using the cosine distance are very different from the ones found with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quantify the similarity between these clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = np.zeros((3, 3))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        similarity_score = jaccard_score(\n",
    "            (agglo_cosine_clusters == i).astype(\"int32\"),\n",
    "            (agglo_eucli_clusters == j).astype(\"int32\"),\n",
    "        )\n",
    "        similarity_scores[i, j] = similarity_score\n",
    "        print(f\"Similarity score for clusters {i} vs {j}: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    similarity_scores,\n",
    "    columns=[\"Cluster 0\", \"Cluster 1\", \"Cluster 2\"],\n",
    "    index=[\"Cluster 0\", \"Cluster 1\", \"Cluster 2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = rand_score(agglo_cosine_clusters, agglo_eucli_clusters)\n",
    "adjusted_rand = adjusted_rand_score(agglo_cosine_clusters, agglo_eucli_clusters)\n",
    "print(f\"Rand score: {rand}\")\n",
    "print(f\"Adjusted rand score: {adjusted_rand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agglo_eucli_clusters == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the samples are gathered in the same cluster using the euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"data/gdsc_dr.csv\", index_col=0, header=0)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.transpose()\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging training data on indexes\n",
    "train = pd.merge(\n",
    "    df_train_scaled, labels[\"doxorubicin\"], left_index=True, right_index=True\n",
    ")\n",
    "train[\"doxorubicin\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping missing values\n",
    "train = train.dropna()\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling train labels\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "label_scaler = StandardScaler()\n",
    "train[\"doxorubicin\"] = label_scaler.fit_transform(\n",
    "    train[\"doxorubicin\"].values.reshape(-1, 1)\n",
    ").reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data scaled using the trained scalertest\n",
    "np_test_scaled = features_scaler.transform(df_test)\n",
    "df_test_scaled = pd.DataFrame(\n",
    "    np_test_scaled, index=df_test.index, columns=df_test.columns\n",
    ")\n",
    "test = pd.merge(\n",
    "    df_test_scaled, labels[\"doxorubicin\"], left_index=True, right_index=True\n",
    ")\n",
    "test[\"doxorubicin\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"doxorubicin\"] = label_scaler.transform(\n",
    "    test[\"doxorubicin\"].values.reshape(-1, 1)\n",
    ").reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit learn provides an implementation for the lasso regression that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[\"doxorubicin\"]\n",
    "X = train.drop(\"doxorubicin\", axis=1)\n",
    "Y_test = test[\"doxorubicin\"]\n",
    "X_test = test.drop(\"doxorubicin\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Lasso(alpha=0.1, max_iter=10000)\n",
    "reg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on train set with Spearman correlation\n",
    "Y_pred = reg.predict(X_test)\n",
    "res = spearmanr(Y_test.values, Y_pred)\n",
    "print(f\"Spearman correlation on train set: {res.statistic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of coefficients: {len(reg.coef_)}\")\n",
    "print(f\"Number of non-zero coefficients (selected features): {np.sum(reg.coef_ != 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now iterating over different values for $\\alpha \\in$ [0.01, 0.1, 0.3, 0.5, 0.9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_non_zero = []\n",
    "mse_scores = []\n",
    "spearman_scores = []\n",
    "alphas = [0.01, 0.1, 0.3, 0.5, 0.9]\n",
    "for alpha in alphas:\n",
    "    reg = Lasso(alpha=alpha, max_iter=10000)\n",
    "    reg.fit(X, Y)\n",
    "    mse_scores.append(mean_squared_error(Y_test, reg.predict(X_test)))\n",
    "    spearman_scores.append(spearmanr(Y_test.values, reg.predict(X_test)).statistic)\n",
    "    nbr_non_zero.append(np.sum(reg.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that spearman correlation rank is not defined for higher $\\alpha$ values because the regression output is close to a constant, as the number of selected features decreases to close to 0, so the coefficient diverges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of number of non zero coefficients\n",
    "sns.lineplot(x=alphas, y=nbr_non_zero, label=\"Number of selected features\", marker=\"o\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Number of non-zero coefficients\")\n",
    "plt.xticks(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the nested CV, we start anew from the unsplit and un scaled dataset, as the nested process involves splitting into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def spearman_scorer(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    res = spearmanr(y_true, y_pred).statistic\n",
    "    if res is np.nan:\n",
    "        return 1000\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpreprocessed features and labels\n",
    "labels = pd.read_csv(\"data/gdsc_dr.csv\", index_col=0, header=0).transpose()[\n",
    "    \"doxorubicin\"\n",
    "]\n",
    "features = pd.read_csv(\"data/gdsc_expr_postCB.csv\", index_col=0, header=0).transpose()\n",
    "df_full = pd.merge(features, labels, left_index=True, right_index=True)\n",
    "print(f\"Dataset shape : {df_full.values.shape}\")\n",
    "print(f\"Number of missing values : {df_full.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"reg__alpha\": [0.01, 0.1, 0.3, 0.5, 0.9]}\n",
    "pipe = Pipeline(steps=[(\"scaler\", StandardScaler()), (\"reg\", Lasso(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_full[\"doxorubicin\"]\n",
    "X = df_full.drop(\"doxorubicin\", axis=1)\n",
    "\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "\n",
    "clf = GridSearchCV(estimator=pipe, param_grid=p_grid, cv=inner_cv)\n",
    "nested_scores = cross_validate(\n",
    "    clf,\n",
    "    X=X,\n",
    "    y=Y,\n",
    "    cv=outer_cv,\n",
    "    scoring={\"mse\": make_scorer(mean_squared_error), \"spearman\": spearman_scorer},\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(nested_scores, \"nested_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "nested_scores = joblib.load(\"nested_scores.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(nested_scores[\"test_mse\"])\n",
    "avg_spearman = np.mean(nested_scores[\"test_spearman\"])\n",
    "print(f\"Average MSE: {avg_mse:.3f}\")\n",
    "print(f\"Average Spearman correlation: {avg_spearman:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse = np.mean(nested_scores[\"train_mse\"])\n",
    "avg_spearman = np.mean(nested_scores[\"train_spearman\"])\n",
    "print(f\"Average MSE: {avg_mse:.3f}\")\n",
    "print(f\"Average Spearman correlation: {avg_spearman:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alphas = []\n",
    "for est in nested_scores[\"estimator\"]:\n",
    "    best_alphas.append(est.best_params_[\"reg__alpha\"])\n",
    "print(best_alphas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecsehw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
